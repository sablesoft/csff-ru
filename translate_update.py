#!/usr/bin/env python3

# === 1. –ò–º–ø–æ—Ä—Ç—ã –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ ===
import csv
import os
import sys
import openai
from pathlib import Path
from datetime import datetime

CHUNK_SIZE = 50
DELIMITER = "|"
DEBUG_DIR = "debug"
PROMPT_FILE = "prompt.txt"
RESUME_FILE = os.path.join(DEBUG_DIR, "resume_state.txt")
MODEL = "gpt-4o"

# === 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ API –∫–ª—é—á–∞ ===
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    print("‚ùå Set OPENAI_API_KEY in environment.")
    sys.exit(1)

# === 3. –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∏ –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ ===
if len(sys.argv) != 3:
    print("Usage: python translate_full_file.py <source.csv> <lang_code>.csv")
    sys.exit(1)

src_file = sys.argv[1]
dst_file = sys.argv[2]

lang_code = Path(dst_file).stem.split("-")[0]
date_str = datetime.now().strftime("%Y%m%d")
output_file = f"{lang_code}-{date_str}.csv"

os.makedirs(DEBUG_DIR, exist_ok=True)
translated_rows = []

# === 4. –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ CSV ===
with open(src_file, newline='', encoding='utf-8') as f:
    reader = list(csv.reader(f))
    print(f"üì• –ó–∞–≥—Ä—É–∑–∏–ª–∏ {len(reader)} —Å—Ç—Ä–æ–∫ –∏–∑ {src_file}")

# === 5. –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å) ===
existing_translations = {}
if os.path.exists(dst_file):
    with open(dst_file, newline='', encoding='utf-8') as f:
        for row in csv.reader(f):
            if len(row) >= 3:
                existing_translations[row[0]] = row[2]
    print(f"üìö –ù–∞–π–¥–µ–Ω–æ {len(existing_translations)} —Å—Ç—Ä–æ–∫ –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º –ø–µ—Ä–µ–≤–æ–¥–µ")

# === 6. –ó–∞–≥—Ä—É–∑–∫–∞ —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞ ===
with open(PROMPT_FILE, encoding='utf-8') as f:
    prompt_template = f.read()

# === 7. –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è resume ===
resume_index = 0
if os.path.exists(RESUME_FILE):
    with open(RESUME_FILE) as f:
        resume_index = int(f.read().strip())
        print(f"üîÅ Resume: –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å —á–∞–Ω–∫–∞ #{resume_index}")

if resume_index == 0 and os.path.exists(output_file):
    os.remove(output_file)

# === 8. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤ ===
chunks = [reader[i:i + CHUNK_SIZE] for i in range(0, len(reader), CHUNK_SIZE)]

# === 9. –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–æ–≤ ===
for chunk_index, chunk in enumerate(chunks):
    if chunk_index < resume_index:
        continue

    print(f"‚öôÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞ {chunk_index + 1}/{len(chunks)}")

    keys, english_texts, reused_translations = [], [], []
    missing_translations = []

    for row in chunk:
        if len(row) < 2:
            print(f"‚ùå –û—à–∏–±–∫–∞: —Å—Ç—Ä–æ–∫–∞ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è: {row}")
            sys.exit(1)
        key, en = row[0], row[1]
        keys.append(key)
        english_texts.append(en)
        ru = existing_translations.get(key)
        if ru:
            reused_translations.append(ru)
        else:
            reused_translations.append(None)
            missing_translations.append(en)

    # === 10. –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ ===
    debug_input_file = f"{DEBUG_DIR}/batch_{chunk_index + 1:03d}_gpt_input.txt"
    debug_output_file = f"{DEBUG_DIR}/batch_{chunk_index + 1:03d}_gpt_output.txt"
    debug_summary_file = f"{DEBUG_DIR}/batch_{chunk_index + 1:03d}_debug_summary.txt"

    translated_lines = reused_translations.copy()

    translated_text = None
    if os.path.exists(debug_output_file):
        print(f"‚ö°Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥: batch_{chunk_index + 1:03d}_output.txt")
        with open(debug_output_file, encoding='utf-8') as f:
            translated_text = f.read()
    elif missing_translations:
        try:
            prompt = prompt_template.replace("{lang}", lang_code).replace("{sep}", DELIMITER)
            joined_input = DELIMITER.join(missing_translations)

            with open(debug_input_file, "w", encoding="utf-8") as f:
                f.write(joined_input)

            client = openai.OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model=MODEL,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": joined_input}
                ],
                temperature=0.3
            )
            translated_text = response.choices[0].message.content
            with open(debug_output_file, "w", encoding='utf-8') as f:
                f.write(translated_text)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —á–∞–Ω–∫–µ {chunk_index}: {e}")
            sys.exit(1)

    if translated_text:
        new_translations = translated_text.split(DELIMITER)
        if len(new_translations) != len(missing_translations):
            print(f"‚ùå –û—à–∏–±–∫–∞: –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫: {len(missing_translations)} ‚Üí {len(new_translations)}")
            sys.exit(1)
        idx = 0
        for i, val in enumerate(translated_lines):
            if val is None:
                translated_lines[i] = new_translations[idx]
                idx += 1

    # === 11. –ó–∞–ø–∏—Å—å —Ç–∞–±–ª–∏—Ü—ã –ª–æ–≥–æ–≤ –∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ ===
    with open(debug_summary_file, "w", encoding='utf-8') as f:
        for i in range(len(chunk)):
            key = keys[i]
            en = english_texts[i]
            ru = translated_lines[i]
            status = "OLD" if existing_translations.get(key) else "NEW"
            f.write(f"{i+1:02d}|{status}|{key}|{en}|{ru}\n")

    with open(output_file, "a", encoding='utf-8', newline='') as f:
        writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)
        for i in range(len(chunk)):
            writer.writerow([keys[i], english_texts[i], translated_lines[i]])

    with open(RESUME_FILE, "w") as f:
        f.write(str(chunk_index + 1))
#     break  # ‚õîÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —á–∞–Ω–∫ –∏ –≤—ã—Ö–æ–¥–∏–º

# === 12. –§–∏–Ω–∞–ª ===
print(f"‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à—ë–Ω: {output_file}")
print("üìÇ –û—Ç–ª–∞–¥–æ—á–Ω—ã–µ —Ñ–∞–π–ª—ã: debug/")
